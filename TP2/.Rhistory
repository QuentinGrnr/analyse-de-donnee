row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
# Création du vecteur de couleurs pour class.kmeans
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
# Tracer le PCA en coloriant selon les résultats de k-means
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
# En ´eliminant le bruit #
# res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=12, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
# Création du vecteur de couleurs pour class.kmeans
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
# Tracer le PCA en coloriant selon les résultats de k-means
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
# Création du vecteur de couleurs pour class.kmeans
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
# Tracer le PCA en coloriant selon les résultats de k-means
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
# Création du vecteur de couleurs pour class.kmeans
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
# Tracer le PCA en coloriant selon les résultats de k-means
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
# Création du vecteur de couleurs pour class.kmeans
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
# Tracer le PCA en coloriant selon les résultats de k-means
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
# En ´eliminant le bruit #
# res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=12, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
# En ´eliminant le bruit #
res.hcpc <- HCPC(res.pca, nb.clust = 3)
plot.HCPC(res.hcpc, choix = "ind")
quanti.sup=13:16, quali.sup=17)
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# Sans perte d’information #
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
# En ´eliminant le bruit #
res.hcpc <- HCPC(res.pca, nb.clust = 3)
plot.HCPC(res.hcpc, choix = "ind")
quanti.sup=13:16, quali.sup=17)
# PCA without information loss
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
# Removing noise and performing HCPC with 3 clusters
res.hcpc <- HCPC(res.pca, nb.clust = 3)
# Plotting the results
plot.HCPC(res.hcpc, choice = "ind")
library(FactoMineR)
library(factoextra)
temperature0 <- read.table(file.choose(),header=TRUE, sep=";", dec=".",
row.names=1)
temperature <- temperature0[-(24:35),1:12]
# Si les variables consid´er´ees ne sont pas homog`enes en variance, il est utile
# de r´eduire (standardiser) les variables avant une classification.
#temperature <- scale(temperature)
res.hclust <- hclust(dist(temperature),method="ward")
plot(res.hclust,xlab="nb de classes",ylab="Hauteur")
cl.hclust <- identify(res.hclust)
nb <- length(cl.hclust)
class.hclust <- rep(0,dim(temperature)[1])
for (i in 1:nb) {class.hclust[cl.hclust[[i]]] <- i}
resAUX.class <- kmeans(temperature,centers=10)
resAUX.hclust <- hclust(dist(resAUX.class$centers),method="ward")
plot(resAUX.hclust,xlab="nb de classes",ylab="Hauteur")
#####################
# Choisir le nombre de classes : 3,4,5 ?
res.class <- kmeans(temperature,centers=3)
class.kmeans <- res.class$cluster
fviz_cluster(res.class, data = temperature, geom = "point")  # Affichage du clustering avec des points
#################
res.pca <- PCA(temperature0, scale.unit=TRUE, ind.sup=24:35,quanti.sup=13:16,
quali.sup=17)
plot.PCA(res.pca, choix="ind", habillage=17)
res.pca$eig
barplot(res.pca$eig[,1])
boxplot(res.pca$ind$coord)
#############
res.pca = PCA(temperature, scale.unit = T, graph = F)
col.hclust = as.character(factor(class.hclust,levels = 1:5,
labels = c("black","red","green","blue","purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.hclust)
# A comparer avec :
#res.hcpc <- HCPC(temperature)
col.kmeans <- as.character(factor(class.kmeans, levels = 1:5,
labels = c("black", "red", "green", "blue", "purple")))
plot.PCA(res.pca, habillage = T, col.ind = col.kmeans)
###########################
# PCA without information loss
res.pca <- PCA(temperature0, scale.unit=TRUE, ncp=Inf, ind.sup=24:35,
quanti.sup=13:16, quali.sup=17)
# Removing noise and performing HCPC with 3 clusters
res.hcpc <- HCPC(res.pca, nb.clust = 3)
# Plotting the results
plot.HCPC(res.hcpc, choice = "ind")
# training tp2
crime <- read.table(file.choose(), dec=".", row.names = 1)
# training tp2
crime <- read.table("crime.dat", dec=".", row.names = 1)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto")
crime
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
hist(crime$murder)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
hist(crime$murder, col = grey(0.18))
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
hist(crime$murder, col = grey(0.6))
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
source("C:/Users/quent/Desktop/github/analyse-de-donnee/TP2/TP2-Training.R")
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
var(crime) # la commande cov(crime) permet également d'afficher la matrice
# de variance-covariance
cor(crime)
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
cov(crime) # la commande cov(crime) permet également d'afficher la matrice
# de variance-covariance
cor(crime)
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
cov(crime) # la commande cov(crime) permet également d'afficher la matrice
# de variance-covariance
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
plot(crime)
# training tp2
setwd("C:\\Users\\quent\\Desktop\\github\\analyse-de-donnee\\TP2")
crime <- read.table("crime.dat", dec=".", row.names = 1)
names(crime) <- c("murder","rape","robbery","assault","burglary",
"larceny","auto") # rename des vars
crime
summary(crime$murder)
hist(crime$murder, col = grey(0.6))
# etc....
var(crime) # la commande cov(crime) permet également d'afficher la matrice
# de variance-covariance
cor(crime)
plot(crime)
var(crime)
cov(crime)
cor(crime)
plot(crime)
source("C:/Users/quent/Desktop/github/analyse-de-donnee/TP2/TP2-Training.R")
